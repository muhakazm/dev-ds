{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f270d4-4f51-4a69-ba0c-c405be58f17c",
   "metadata": {},
   "source": [
    "KNN (K-Nearest Neighbors)\n",
    "- Type: Classification (also regression)\n",
    "- How it works: Looks at the 'k' closest data points (neighbors) to a new input and predicts based on the majority class among them.\n",
    "- Intuition: \"Tell me who your neighbors are, and I’ll tell you who you are.\"\n",
    "- Pros: Simple, no training phase.\n",
    "- Cons: Slow with large datasets, sensitive to irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acc70f-fb97-4262-8860-12ff676b91c3",
   "metadata": {},
   "source": [
    "SVC (Support Vector Classifier)\n",
    "- Type: Classification\n",
    "- How it works: Finds the best hyperplane that separates data into classes with the maximum margin.\n",
    "- Intuition: Tries to draw the widest possible line between different classes.\n",
    "- Pros: Works well in high-dimensional spaces.\n",
    "- Cons: Not great with large datasets; tuning can be tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764a291-f094-4f1a-881b-5d3135b083a3",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "- Type: Classification and regression\n",
    "- How it works: An ensemble of decision trees where each tree votes, and the majority wins.\n",
    "- Intuition: A crowd of diverse trees gives a better decision.\n",
    "- Pros: Accurate, handles overfitting better than individual trees.\n",
    "- Cons: Slower, less interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baffaa8e-bb9f-4d04-b3ef-b65e7077f34f",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "- Type: Classification (binary or multiclass)\n",
    "- How it works: Uses a logistic (sigmoid) function to model the probability that an input belongs to a particular class.\n",
    "- Intuition: Like linear regression but for classification.\n",
    "- Pros: Fast, interpretable, good baseline model.\n",
    "- Cons: Assumes linearity, can underperform on complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c01223-7646-4dc2-ae26-9fc336ba7721",
   "metadata": {},
   "source": [
    "Decision Tree Classifier\n",
    "- Type: Classification (also regression)\n",
    "- How it works: Splits data into branches based on feature values to reach a decision (leaf).\n",
    "- Intuition: Like playing 20 questions—\"Is it red?\" → yes/no → next question...\n",
    "- Pros: Easy to understand and visualize.\n",
    "- Cons: Prone to overfitting if not pruned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a81410-d1af-4f4e-8db8-61b8e7f9d763",
   "metadata": {},
   "source": [
    "AdaBoost Classifier\n",
    "- Type: Ensemble method (boosting)\n",
    "- How it works: Combines many weak learners (usually decision trees) sequentially, each focusing more on the previous errors.\n",
    "- Intuition: Each learner tries to fix the mistakes of the one before.\n",
    "- Pros: Effective on complex problems.\n",
    "- Cons: Sensitive to noisy data and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a5ab9-8afb-41f7-9674-b16ad7f0d379",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier\n",
    "- Type: Ensemble method (boosting)\n",
    "- How it works: Like AdaBoost, but it builds trees to minimize a loss function using gradient descent.\n",
    "- Intuition: Fixes mistakes step by step by reducing the error gradient.\n",
    "- Pros: Very powerful; used in many winning Kaggle models.\n",
    "- Cons: Computationally expensive, needs tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3a58d-5292-4c8c-8487-ed2080c4433e",
   "metadata": {},
   "source": [
    "Voting Classifier\n",
    "- Type: Ensemble method\n",
    "- How it works: Combines multiple models (can be different types) and makes a prediction based on majority vote (classification) or average (regression).\n",
    "- Intuition: Group decision-making—ask multiple models and go with the majority.\n",
    "- Pros: Can improve performance by combining strengths.\n",
    "- Cons: Requires diverse, well-performing individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a24fbd5-1ab5-452d-8cf4-9062fc3d8feb",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceef628-f2cd-4bb1-9546-890c7a4c7493",
   "metadata": {},
   "source": [
    "## Common Libraries to Import for All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f422fcb-fc2a-4dea-a79d-923b154a3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d555d48-ba6c-453f-944a-552119f0fb86",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)\n",
    "- Library: sklearn.neighbors\n",
    "- Model: KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b54ecf-0cbd-4201-b667-3fdd97e31e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bc8d7-8630-4461-89c8-61e03552bdae",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)\n",
    "- Library: sklearn.svm\n",
    "- Model: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee8f44f-97d1-45cd-b143-edf063a68a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf', C=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128305c-5620-4c41-afb2-dc7c0ddb64da",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "- Library: sklearn.ensemble\n",
    "- Model: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3f302a-26ea-4d4e-ad4b-22d0ee59ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c2f4-0b83-4100-96ef-aaaf3bdea742",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "- Library: sklearn.linear_model\n",
    "- Model: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e17782-82df-4b17-a2fe-6730ae9a202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f05fab-c7af-49b7-9b30-2a890f5fd55a",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "- Library: sklearn.tree\n",
    "- Model: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6af7167-9847-4294-bbd4-ba10125354ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfd0a0-3f39-4ea2-a346-7a2039f10e29",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "- Library: sklearn.ensemble\n",
    "- Model: AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3da59dc-bc1f-45a6-9146-d2a39a464a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bfbd2-2bee-4996-b0f2-882d5c5e58af",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "- Library: sklearn.ensemble\n",
    "- Model: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4312bfa1-f7ba-4685-9cb3-dfb08cea9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637058b4-efae-4414-8784-36684f6ced5d",
   "metadata": {},
   "source": [
    "## Voting Classifier (Ensemble of Models)\n",
    "- Library: sklearn.ensemble\n",
    "- Model: VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58126b3f-5bb3-4a8e-9fce-fb35f0fc24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC(probability=True)\n",
    "model3 = RandomForestClassifier()\n",
    "\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr', model1), ('svc', model2), ('rf', model3)],\n",
    "    voting='soft'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python:ds-gen",
   "language": "python",
   "name": "ds-gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
